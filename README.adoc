// README

Nanopore Basecaller Training
============================

https://github.com/nanoporetech/bonito

:toc:
:toc-placement: preamble
:toclevels: 1
:showtitle:

// Setting up conda environment

== Getting Started

[source,shell]
----
conda create -n hrlaxh_bonito python=3.8 pip 
conda activate --stack hrlaxh_bonito
----

There are CUDA libraries installed on the powerplant GPU hosts but the runtime libraries, e.g. libcudart.so.11.3 need to be installed into the env of your analysis, which is easiest with conda.


[source,shell]
----
conda install -c anaconda cudatoolkit
----

Change cu113 on the command below to your CUDA version: 
To get cuda version: 

----
[12:03][hrabxw@wkoppg34:~] $ rpm -qa|grep cuda
nvidia-driver-latest-dkms-cuda-libs-520.61.05-1.el7.x86_64
nvidia-driver-latest-dkms-cuda-520.61.05-1.el7.x86_64
----

[source,shell]
----
pip install --no-cache-dir --extra-index-url https://download.pytorch.org/whl/cu113 ont-bonito
pip install -r bonito/requirements.txt
----

=== Download Models
[source,shell]
----
bonito download --models --show
bonito download --models --all
----

You can cancel it at the training data (I think?). 

=== Create a minimap2 index
[source,shell]
----
minimap2 -d index.mmi assembly.fasta
----

=== Basecall with --save-ctc
==== Trying this now
[source,shell]
----
bonito basecaller dna_r9.4.1_e8_sup@v3.3 ~/all_fast5/ --batchsize 384 --reference index.mmi --save-ctc --recursive --device "cuda:0" --alignment-threads 16 > basecalled-default-model/basecalls.sam
----

NOTE: It has to be in the order as above, or the ctc will not save! basecaller model filepath THEN options.

Default batch size is 32 (I'm 90% certain). Best to try and increase it. When it crashes from memory, best to killall bonito from another shell. I can get batchsize of 384 and it cuts a little over half an hour off on my dataset (51Gb of fast5 files). And we can work with that number on the following steps.


